{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCK506 Deep Learning Group Project\n",
    "To train a *Convolutional Neural Network* (CNN) model to be able to detect healthy lungs from pneumonia infected ones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "=================\n",
    "1. [Import Libraries](#Import-Libraries)\n",
    "2. [Data Preprocessing](#Data-Preprocessing)\n",
    "    1. [Load Data](#Load-Data)\n",
    "    2. [Understanding the Data](#Understanding-the-Data)\n",
    "    3. [Data Visualization](#Data-Visualization)\n",
    "    4. [Check for Imbalance Data](#Check-for-Imbalance-Data)\n",
    "    5. [Data Augmentation](#Data-Augmentation)\n",
    "    6. [Dataloader for Batching](#Dataloader-for-Batching)\n",
    " 3. [Model Development](#Model-Development)\n",
    "    1. [Build the CNN Model](#Build-the-CNN-Model)\n",
    "    2. [Train the CNN Model](#Train-the-CNN-Model)\n",
    "    3. [Evaluate the CNN Model](#Evaluate-the-CNN-Model)\n",
    "    4. [Save the CNN Model](#Save-the-CNN-Model)\n",
    " 4. [Model Testing](#Model-Testing)\n",
    "    1. [Load the CNN Model](#Load-the-CNN-Model)\n",
    "    2. [Test the CNN Model](#Test-the-CNN-Model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import zipfile\n",
    "\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip File into data folder\n",
    "- Download the dataset from [Kaggle](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) and extract it to the same directory as this notebook.\n",
    "- To re-extract the dataset, delete the data folder and run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder already exists\n"
     ]
    }
   ],
   "source": [
    "\"\"\" if not os.path.exists('data'):\n",
    "    DATA_EXIST = False\n",
    "    os.makedirs('data')\n",
    "else:\n",
    "    DATA_EXIST = True\n",
    "    EXTRACT_FROM_ZIP = False\n",
    "    print('Data folder already exists')\n",
    "\n",
    "# Check if downloaded data is correct\n",
    "FILENAME = 'archive.zip'\n",
    "SHA256SUM ='f569fe885b0f921e836f3d6bcc8d7b3442f5e0ca4db4533d06b8cf25d2114ea1'\n",
    "\n",
    "if os.path.exists(FILENAME) and not DATA_EXIST:\n",
    "    with open(FILENAME, 'rb') as f:\n",
    "        read_bytes = f.read() # read entire file as bytes\n",
    "        READABLE_HASH = hashlib.sha256(read_bytes).hexdigest()\n",
    "        if READABLE_HASH != SHA256SUM:\n",
    "            print('Data corrupted, please download again')\n",
    "            os.remove(FILENAME)\n",
    "            EXTRACT_FROM_ZIP = False\n",
    "        else:\n",
    "            EXTRACT_FROM_ZIP = True # Ready to extract data from zip file\n",
    "\n",
    "folder_to_extract = ['chest_xray/test', 'chest_xray/train', 'chest_xray/val']\n",
    "\n",
    "# Extract data from zip file\n",
    "if not DATA_EXIST and EXTRACT_FROM_ZIP:\n",
    "    with zipfile.ZipFile(FILENAME, 'r') as zip_ref:\n",
    "        for fol in folder_to_extract:\n",
    "            for file in zip_ref.namelist():\n",
    "                if file.startswith(fol):\n",
    "                    zip_ref.extract(file, 'data')\n",
    "    for fol in folder_to_extract:\n",
    "        os.rename('data/'+fol, 'data/'+fol.split('/')[1])\n",
    "    os.rmdir('data/chest_xray') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './data/test/'\n",
    "test_dir = './data/val/'\n",
    "\n",
    "target_size = (224,224)\n",
    "\n",
    "# define the data generator and normalize pixel values\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# load and iterate over the image data in batches\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=32,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=32,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Imbalance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "Alter the training data with the following transformations:\n",
    "- Randomly rotate some training images by 10 degrees\n",
    "- Randomly resize and crop some training images\n",
    "\n",
    "The purpose of data augmentation is to increase the number of training data to improve the performance and ability of the model to generalize, invariant to the changes in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader for Batching\n",
    "Load the data into batches of images and labels using PyTorch's DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the CNN Model\n",
    "Use the training data to train the model with CNN which has the minimum loss and maximum accuracy for detecting the images with pneumonia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sequential: This is a Keras model type that allows you to build a model by adding layers sequentially. In this case, we use it to define a feedforward neural network.\n",
    "\n",
    "2. Conv2D: This layer performs convolution on the input image. In this case, we use a 2D convolution with a kernel size of 3x3 and 32 output filters. We also specify the relu activation function to introduce non-linearity into the model. The input_shape parameter specifies the shape of the input data, which is a 224x224 RGB image with single channels (monochrome).\n",
    "\n",
    "3. MaxPooling2D: This layer performs max pooling on the output of the convolution layer. In this case, we use a 2x2 pooling window to reduce the spatial dimensions of the output by a factor of 2.\n",
    "\n",
    "4. We repeat steps 2 and 3 twice with different numbers of output filters (64 and 128) and pooling windows to extract higher-level features from the image.\n",
    "\n",
    "5. Flatten: This layer flattens the output of the convolutional layers into a 1D array, which can be fed into a fully connected layer.\n",
    "\n",
    "6. Dense: This layer is a fully connected layer that computes the output of the network using a linear transformation of the input followed by a non-linear activation function. In this case, we use a dense layer with 128 units and the relu activation function.\n",
    "\n",
    "7. Dropout: This layer applies dropout regularization to the output of the previous layer. Dropout randomly sets a fraction of the output units to zero during training, which helps prevent overfitting.\n",
    "\n",
    "8. We add another dense layer with 2 units and the softmax activation function as the output layer. The softmax function normalizes the output so that it represents a probability distribution over the two output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN Model\n",
    "Choose:\n",
    "- Number of convolution-pooling building blocks,\n",
    "- The strides, padding and activation function that give you the maximum accuracy,\n",
    "- A solution to avoid overfitting problem in your code. --> Regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SDG as the optimizer\n",
    "- Created a new SGD object with a learning rate of 0.01 and a momentum of 0.9. SGD shold have better stability compared to Adaam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with SGD optimizer\n",
    "sgd = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and Tune the CNN Model\n",
    "Use validation dataset to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_generator, verbose=0) \n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('xray_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the CNN Model\n",
    "Use the test dataset after the final tuning to obtain the maximum test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
